---
layout: post
title: Acropora pulchra RNA-seq Bioinformatic Workflow
date: 2024-01-01
category: [ Code ]
tag: [ RNA-seq, Bioinformatics, Acropora pulchra de novo transcriptome ]
projects: Heatwave - Gametogenesis ; E5 - Molecular Underpinnings
---

## Mapping sequences from *Acropora pulchra* coral samples from adult colonies exposed to marine heatwave conditions in Moorea, French Polynesia in March/April 2022 and their offspring (larvae) collected from coral spawning in October 2022 to a *Acropora pulchra de novo* transcriptome.


### **Goal**

The following document contains the bioinformatic pipeline used for cleaning, aligning and assembling our raw RNA sequences. The goal is to map the adult and larval sequences to a compiled *Acropora pulchra de novo* transcriptome. All metadata and information for these projects can be found in this [repository](https://github.com/daniellembecker/A.pul_Heatwave/tree/master) and in these notebook posts of the [*de novo* transcriptome assembly](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-08-31-Acropora-pulchra-denovo-transcriptome.md) and the [extraction protcol](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-04-25-Acropora-pulchra-transcriptome-extraction-concentration.md) for the samples used in the assembly. These commands were compiled into bash scripts to run on the URI HPC [Andromeda](https://its.uri.edu/research-computing/using-andromeda/) server.

### Metadata for submitted sequences

[Sequence samples metadata](https://github.com/daniellembecker/A.pul_Heatwave/blob/master/bioinformatics/heatwave_CGA_extractions.csv)


# 1) Obtain *de novo* transcriptome

I am using the *Acropora pulchra* *de novo* transcriptome assembled in [November 2023](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-08-31-Acropora-pulchra-denovo-transcriptome.md), following methods outlined for [transcript sequence reconstruction from RNA-Seq: reference generation and analysis with Trinity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875132/).

Location on Andromeda, the HPC server for URI:
```
cd /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta

```


## Make folder structure for sequence mapping analysis
```
cd /data/putnamlab/dbecks/

mkdir Heatwave_A.pul_2022Project
cd Heatwave_A.pul_2022Project

mkdir data
mkdir scripts

cd data
mkdir raw

```

## Copy already downloaded raw sequence files from putnam lab main storage in Andromeda


```
cp -r /data/putnamlab/KITT/hputnam/20231214_Apulchra_RiboDepletion/* /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw
```

# 2) Check file integrity

a) Count all files to make sure all downloaded

```
ls -1 | wc -l
```

b) Verify data transfer integrity with md5sum

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/check_transfer.sh
```

```
#!/bin/bash ###creating slurm script
#SBATCH -t 24:00:00 ###give script 24 hours to run
#SBATCH --nodes=1 --ntasks-per-node=1 ###on server, different nodes you can use for processing power, node just do one task
#SBATCH --export=NONE
#SBATCH --mem=100GB ###in server allocate 100GB amount of memory
#SBATCH --account=putnamlab ###primary account
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw ###path


md5sum /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw*.gz > URIcheckmd5.md5

md5sum /data/putnamlab/KITT/hputnam/20231214_Apulchra_RiboDepletion/*.gz > URIcheckmd5.md5

```

```
sbatch check_transfer.sh
Submitted batch job 253687
```

### Checksum from Genewiz

```
b4a85239e88aba5d1762d7e90a9d70d8  ./12_R1_001.fastq.gz
eab831185c3b8ca72cf3914f57fd7330  ./12_R2_001.fastq.gz
7f620547442556c977ed6e64322ad3b4  ./16_R1_001.fastq.gz
96343dd00c1ea31d0f35af312db01405  ./16_R2_001.fastq.gz
1c05cc100907fa24681921aa520721ff  ./20_R1_001.fastq.gz
5ba8e2613376b60d42d4a79de32eeafe  ./20_R2_001.fastq.gz
4b29ffe9c1a711864d2615ba2dafbe06  ./248_R1_001.fastq.gz
332babdf0cce128c46dddf2242923d8d  ./248_R2_001.fastq.gz
32d3be14d0c8eaff9f986a8198dbf101  ./249_R1_001.fastq.gz
955885f77f56a52cfec0f5dbe1bb5aa6  ./249_R2_001.fastq.gz
e970c9fef559d883400616144469740f  ./24_R1_001.fastq.gz
1ce920d6100cb0e97efdd7acb1206afe  ./24_R2_001.fastq.gz
a9dd31f2aca0656e855990b253a216d8  ./250_R1_001.fastq.gz
b6821db41d50b1d0c01f39e1ef9fd40e  ./250_R2_001.fastq.gz
25c2235a292e2a20bf6334d74c164855  ./260_R1_001.fastq.gz
f15e2c1bb8959aa686d4848db6535c53  ./260_R2_001.fastq.gz
d424bde716d0a388d4b82910490b16f9  ./261_R1_001.fastq.gz
723bcabf15e03805e3d45819d2c8a9cf  ./261_R2_001.fastq.gz
ea8944531c703a3ae2eb92b6add58944  ./262_R1_001.fastq.gz
ae433007a1a10464af2b41bef690d7ed  ./262_R2_001.fastq.gz
de405dc4452fb440b2bd4edbc9c30a87  ./5_R1_001.fastq.gz
1f53cd6cbb43668a3bffd094b73c9ad6  ./5_R2_001.fastq.gz
5d73e8c968f198e279b68668ef3fb50f  ./8_R1_001.fastq.gz
d2de35adcc456517be1e09bb097aeadb  ./8_R2_001.fastq.gz
```

c) Verify data integrity with md5sum

Cross-reference the checksum document from GENEWIZ with the data we have on our computer

With a small amount of files, able to first cross-check that the sequences matched between both files on the desktop

Use the code below in terminal to cross-check the files and compare for sanity check

```
in directory: /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw

md5sum -c Genewiz_Provided.md5
```

Should output 'OK' next to each file name

d) Count number of reads per file using the code after @ in fastq.gz files (e.g.,@GWNJ).

```
zgrep -c "@A01940" *.gz > raw_seq_counts

```


```

12_R1_001.fastq.gz:22077183
12_R2_001.fastq.gz:22077183
16_R1_001.fastq.gz:21806397
16_R2_001.fastq.gz:21806397
20_R1_001.fastq.gz:22366560
20_R2_001.fastq.gz:22366560
248_R1_001.fastq.gz:24234533
248_R2_001.fastq.gz:24234533
249_R1_001.fastq.gz:24655232
249_R2_001.fastq.gz:24655232
24_R1_001.fastq.gz:23762178
24_R2_001.fastq.gz:23762178
250_R1_001.fastq.gz:21345210
250_R2_001.fastq.gz:21345210
260_R1_001.fastq.gz:26117186
260_R2_001.fastq.gz:26117186
261_R1_001.fastq.gz:24168048
261_R2_001.fastq.gz:24168048
262_R1_001.fastq.gz:25536072
262_R2_001.fastq.gz:25536072
5_R1_001.fastq.gz:23140700
5_R2_001.fastq.gz:23140700
8_R1_001.fastq.gz:23792081
8_R2_001.fastq.gz:23792081

```

# 3) Run FastQC on sequences

a) Make folders for raw FastQC results and scripts

b) Write script for checking quality with FastQC and submit as job on Andromeda

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/fastqc_raw.sh
```

```  
#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mem=100GB
#SBATCH --mail-type=BEGIN,END,FAIL #email you when job starts, stops and/or fails
#SBATCH --mail-user=danielle_becker@uri.edu #your email to send notifications
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw
#SBATCH --error="script_error" #if your job fails, the error report will be put in this file
#SBATCH --output="output_script" #once your job is completed, any final job report comments will be put in this file

module load FastQC/0.11.9-Java-11

for file in /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw/*.gz
do
fastqc $file --outdir /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw/qc
done
```

```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/fastqc_raw.sh

Submitted batch job 291946
```



c) Make sure all files were processed

```
ls -1 | wc -l

#48

```

## Combined QC output into 1 file with MultiQC

```
module load MultiQC/1.9-intel-2020a-Python-3.8.2

multiqc /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw/qc

```

c) Copy MultiQC files to local computer

```
scp -r danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw/qc/multiqc_report.html /Users/Danielle/Desktop/Putnam_Lab/A.pul_Heatwave/bioinformatics/original_fastqc

```


# 4) Trim and clean reads

a) Make trimmed reads folder in all other results folders

```

mkdir data/trimmed
cd trimmed

```

c) Write script for Trimming and run on Andromeda

#Run fastp on files
#Trims 5bp from 5' end of all reads
#Trims poly G, if present

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/trim.sh
```

```
#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mem=100GB
#SBATCH --mail-type=BEGIN,END,FAIL #email you when job starts, stops and/or fails
#SBATCH --mail-user=danielle_becker@uri.edu #your email to send notifications
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/raw
#SBATCH --error="script_error" #if your job fails, the error report will be put in this file
#SBATCH --output="output_script" #once your job is completed, any final job report comments will be put in this file

module load fastp/0.23.2-GCC-11.2.0

array1=($(ls *R1*.fastq.gz)) #Make an array of sequences to trim
for i in ${array1[@]}; do
fastp --in1 ${i} --in2 $(echo ${i}|sed s/_R1/_R2/) --detect_adapter_for_pe --trim_poly_g --trim_front1 15 --trim_front2 15 --qualified_quality_phred 20 --unqualified_percent_limit 5 --out1 ../trimmed/${i} --out2 ../trimmed/$(echo ${i}|sed s/_R1/_R2/)  
done

```
```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/trim.sh

Submitted batch job 292306

#first two runs with different trimming paramaters resulted in errors for per sequence qc content, so using --qualified_quality_phred 15 --unqualified_percent_limit 5 to --qualified_quality_phred sets the threshold for considering a base as high-quality (default is 15, you can adjust as needed).
--unqualified_percent_limit filters out reads with too many low-quality bases.
```


# 5) Check quality of trimmed files

a) Check number of files in /trimmed directory

```
ls -1 | wc -l
#24
```


b) Check number of reads in /trimmed directory

```
zgrep -c "@A01940" *.gz > trimmed_seq_counts

12_R1_001.fastq.gz:19797178
12_R2_001.fastq.gz:19797178
16_R1_001.fastq.gz:19557856
16_R2_001.fastq.gz:19557856
20_R1_001.fastq.gz:19986198
20_R2_001.fastq.gz:19986198
248_R1_001.fastq.gz:21556118
248_R2_001.fastq.gz:21556118
249_R1_001.fastq.gz:22043273
249_R2_001.fastq.gz:22043273
24_R1_001.fastq.gz:21277072
24_R2_001.fastq.gz:21277072
250_R1_001.fastq.gz:19038866
250_R2_001.fastq.gz:19038866
260_R1_001.fastq.gz:23396050
260_R2_001.fastq.gz:23396050
261_R1_001.fastq.gz:21707283
261_R2_001.fastq.gz:21707283
262_R1_001.fastq.gz:22781251
262_R2_001.fastq.gz:22781251
5_R1_001.fastq.gz:20876524
5_R2_001.fastq.gz:20876524
8_R1_001.fastq.gz:21284631
8_R2_001.fastq.gz:21284631


```


c) Run FastQC on trimmed data
```
mkdir trimmed_qc

```
```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/fastqc_trimmed.sh
```

```  
#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mem=100GB
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/trimmed_qc
#SBATCH --error="script_error"
#SBATCH --output="output_script"

module load FastQC/0.11.9-Java-11

for file in /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/*.gz
do
fastqc $file --outdir /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/trimmed_qc
done
```

```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/fastqc_trimmed.sh

Submitted batch job 292337

```


d) Run MultiQC on trimmed data
```
module load MultiQC/1.9-intel-2020a-Python-3.8.2
multiqc /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/trimmed_qc
```
```
scp -r danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/multiqc_report.html /Users/Danielle/Desktop/Putnam_Lab/A.pul_Heatwave/bioinformatics/trimmed_fastqc

```

# 6) Align reads

a) Generate transcriptome index

### HiSat2 Align reads to transcriptome
[HiSat2](https://daehwankimlab.github.io/hisat2/main/)
[HiSat2 Github](https://github.com/DaehwanKimLab/hisat2)


```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Hisat2_transcriptome_build.sh
```

```
#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mem=100GB
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/refs
#SBATCH --error="script_error"
#SBATCH --output="output_script"

module load HISAT2/2.2.1-gompi-2022a

hisat2-build -f /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta Apul_trans_ref

```
```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Hisat2_transcriptome_build.sh

Submitted batch job 292343
```

b) Align reads to transcriptome

```
mkdir mapped
```
```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Hisat2_align2.sh
```

```
#!/bin/bash
#SBATCH -t 72:00:00
#SBATCH --nodes=1 --ntasks-per-node=5
#SBATCH --export=NONE
#SBATCH --mem=500GB
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed
#SBATCH -p putnamlab
#SBATCH --cpus-per-task=3
#SBATCH --error="script_error"
#SBATCH --output="output_script"


module load HISAT2/2.2.1-gompi-2022a

#Aligning paired end reads
#Has the R1 in array1 because the sed in the for loop changes it to an R2. SAM files are of both forward and reverse reads
#-p increases threads on server, --rna-strandness RF forward and reverse, -dta downstream transcriptome analysis, -q reads are fastq files, -x location of ref -S where to output sam files

for read_pair in *_R1_001.fastq.gz; do
    base_name=$(basename "$read_pair" _R1_001.fastq.gz)
    hisat2 -p 48 --rna-strandness RF --dta -q -x /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/refs/Apul_trans_ref -1 "$read_pair" -2 "${base_name}_R2_001.fastq.gz" -S "/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/mapped/${base_name}.sam"
done


```

```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Hisat2_align2.sh

Submitted batch job 292352


#Download alignment statistics information from mapping, will be the output from your script above, even though it is a mapped output, you are in the trimmed folder here

scp -r danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/script_error /Users/Danielle/Desktop/Putnam_Lab/A.pul_Heatwave/bioinformatics/alignment_statistics

```


#### d) Sort and convert sam to bam and check number of mapped reads and mapping percentages

- Explanation:
  - samtools sort -o sorted.bam aligned.sam: This command sorts the SAM file and creates a sorted BAM file (Trinity_aligned.sorted.bam).
  - samtools index .sorted.bam: This command creates an index for the sorted BAM file. The index file (sorted.bam.bai) is necessary for certain operations and viewers.
  - samtools flagstat .sorted.bam: This command generates statistics about the alignment, including the number of mapped reads and mapping percentages.

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/SAMtoBAM.sh

#There will be lots of .tmp file versions in your folder, this is normal while this script runs and they should delete at the end to make one sorted.bam file
```

```
#!/bin/bash
#SBATCH -t 72:00:00
#SBATCH --nodes=1 --ntasks-per-node=8
#SBATCH --export=NONE
#SBATCH --mem=500GB
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/mapped
#SBATCH --cpus-per-task=3
#SBATCH --error="script_error"
#SBATCH --output="output_script"

module load SAMtools/1.16.1-GCC-11.3.0 #Preparation of alignment for assembly: SAMtools

# Directory containing SAM files
sam_directory="/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/mapped/"

# Create a directory for the results
mkdir -p "${sam_directory}/results"

# Process each SAM file in the directory
for sam_file in "$sam_directory"/*.sam; do
    if [ -f "$sam_file" ]; then
        # Extract sample name from the file
        sample_name=$(basename "${sam_file%.sam}")

        # Step 1: Sort the SAM file and convert to BAM
        samtools sort -o "${sam_directory}/results/${sample_name}_sorted.bam" "$sam_file"

        # Step 2: Index the BAM file
        samtools index "${sam_directory}/results/${sample_name}_sorted.bam"

        # Step 3: Check Mapping Statistics
        samtools flagstat "${sam_directory}/results/${sample_name}_sorted.bam" > "${sam_directory}/results/${sample_name}_flagstat.txt"

        echo "Processed: ${sample_name}"
        echo "------------------------"
    fi
done

```

```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/SAMtoBAM.sh

Submitted batch job 292360

```

**Alignment statistics**

```
Can look into individual statistics for each one.

Explanation, example 262_flagstat.txt:

1. Total Reads:
  - 123140253 + 0 in total (QC-passed reads + QC-failed reads): Indicates the total number of reads, including both QC-passed and QC-failed reads. In this case, there are 123,140,253 reads in total.

2. Primary and Secondary Alignments:
  - 45562502 + 0 primary primary: The number of primary alignments. These are the primary alignment records for each read. In this case, there are 45562502 primary alignments.
  - 77577751 + 0 secondary: The number of secondary alignments.
  - Secondary alignments can occur for reads that map equally well to multiple locations in the reference genome.

3. Supplementary Alignments:
  - 0 + 0 supplementary: The number of supplementary alignments. - Supplementary alignments are used to represent chimeric or novel splice junctions.

4. Duplicates:
  - 0 + 0 duplicates: The number of duplicate reads. Duplicate reads can result from PCR artifacts and are often removed in quality control.

5. Primary Duplicates:
  - 0 + 0 primary duplicates: The number of duplicate primary reads. This specifically refers to duplicate primary alignment records.

6. Mapped Reads:
  - 119317854 + 0 mapped (96.90% : N/A): The total number and percentage of mapped reads. In this case, 119317854 reads are mapped, and they constitute 96.9% of the total reads.

7. Primary Mapped Reads:
  - 41740103 + 0 primary mapped (91.61% : N/A)
  - The number and percentage of primary mapped reads.
  - Primary mapped reads refer to those reads where the primary alignment is reported.
  - In this case, 41740103 reads are primary mapped, constituting 91.61% of the total reads.

```


#### e) Download mapping percentages and statistics to desktop if you want for individuals

```

scp -r danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/ref_genome_Amil/mapped/*fagstat.txt /Users/Danielle/Desktop/Putnam_Lab/Gametogenesis/bioinformatics/transcriptome

```



# 7) Perform gene counts with Salmon

```
mkdir salmon
cd salmon

```

#Hollie suggested first using bowtie and trinity to build an index and map and conduct gene identification

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/bowtiebuild.sh


#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --mem=100GB
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity

module load Bowtie2/2.4.5-GCC-11.3.0

bowtie2-build -f /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta Apul_denovo

sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/bowtiebuild.sh

Submitted batch job 292412

#have trinity_out_dir.Trinity.fasta.gene_trans_map and bowtie build files in this trinity_out_dir
```

#To include putative gene information in your Trinity analysis, you can use TransDecoder.LongOrfs and TransDecoder.Predict
#First step identifies likely coding regions (long open reading frames or ORFs) in your Trinity transcripts and creates a file named Trinity.fasta.transdecoder_dir/longest_orfs.pep, which contains the predicted protein sequences.

#Second step predicts likely coding regions and identifies potential coding regions using the output from the LongOrfs step and generates several output files in the Trinity.fasta.transdecoder_dir/ directory, including Trinity.fasta.transdecoder.cds (predicted coding sequences) and Trinity.fasta.transdecoder.gff3 (predicted gene structures in GFF3 format).

```

nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/transdecode_predict.sh

#!/bin/bash
#SBATCH -t 24:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --mem=100GB
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/

module load TransDecoder/5.5.0-foss-2020b

TransDecoder.LongOrfs -t /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta

TransDecoder.Predict -t /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta

sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/transdecode_predict.sh

Submitted batch job 292417

#ran well, got .gff3 files, etc. for further gene information
```

#Aligning Reads:
#-seqType <type>: Specify the type of sequencing data (e.g., fa for fasta, fq for fastq).
#-left <left_reads> and -right <right_reads>: Input left and right reads for paired-end data.
#Estimating Abundance:
#-est_method <method>: Specify the method for abundance estimation (e.g., RSEM, eXpress, etc.).
#-aln_method <method>: Specify the alignment method (e.g., bowtie, bowtie2).
#-prep_reference: Prepare the reference for downstream analysis.
#--trinity_mode: Setting --trinity_mode will automatically generate the gene_trans_map and use it.

```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/trinity_map.sh

#!/bin/bash
#SBATCH -t 48:00:00
#SBATCH --nodes=1 --ntasks-per-node=1
#SBATCH --export=NONE
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --mem=300GB
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/mapped

module load Bowtie2/2.4.5-GCC-11.3.0
module load Trinity/2.15.1-foss-2022a
module load SAMtools/1.16.1-GCC-11.3.0


perl $EBROOTTRINITY/trinityrnaseq-v2.15.1/util/align_and_estimate_abundance.pl \
--transcripts /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta  \
--seqType fq \
--SS_lib_type RF \
--prep_reference \
--left /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/5_R1_001.fastq.gz \
--right /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/5_R2_001.fastq.gz  \
--est_method RSEM \
--aln_method bowtie2 \
--trinity_mode \
--output_dir /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/mapped/


sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/trinity_map.sh

Submitted batch job 292607

```

a) Assemble transcripts, merge abundance files, and create gene counts files

###### Salmon is used for de novo transcriptome analysis due to its speed, accuracy, and ability to handle novel transcripts efficiently. In the provided code, the script leverages Salmon to quantify transcript abundances for multiple RNA-seq samples. It starts by assembling transcripts and estimating abundances for each sample individually, followed by merging these quantification results into a consolidated file. The final step involves performing gene-level quantification using the merged abundance information, resulting in a gene counts file suitable for downstream analyses. This approach is useful for understanding gene expression in the absence of a reference genome or annotated transcriptome.

###### [Salmon Github](https://combine-lab.github.io/salmon/)

###### [Method Comparisons](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04198-1)



```
nano /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Salmon_Assemble.sh
```

```
#!/bin/bash
#SBATCH -t 72:00:00
#SBATCH --nodes=1 --ntasks-per-node=5
#SBATCH --export=NONE
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=danielle_becker@uri.edu
#SBATCH --account=putnamlab
#SBATCH -D /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/salmon
#SBATCH --cpus-per-task=3

module load Salmon/1.9.0-gompi-2021b

# Step 1: Index the de novo transcriptome
salmon index -t /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/data/trinity_out_dir/trinity_out_dir.Trinity.fasta -i salmon_index

# Step 2: Quantify transcript abundances for each sample
for fastq_file in /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trimmed/*_R1_001.fastq.gz; do
    sample_name=$(basename "$fastq_file" _R1_001.fastq.gz)
    salmon quant -i salmon_index -l A -1 "$fastq_file" -2 "${sample_name}_R2_001.fastq.gz" -o "${sample_name}_salmon_output"
done

# Step 3: Merge abundance files
salmon quantmerge --quants *_salmon_output -o salmon_merged_quant

# Step 4: Create gene counts file
salmon quant -i salmon_index -l A --geneMap salmon_merged_quant/quant.genes.txt --seqBias --gcBias -o salmon_gene_counts --numBootstraps 30 *_R1_001.fastq.gz *_R2_001.fastq.gz

done
```

```
sbatch /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/scripts/Salmon_Assemble.sh

```


b) Secure-copy gene counts onto local computer, make sure to open a separate command shell outside of Andromeda on your own terminal

```
#copy gene count matrix

scp danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/mapped/GTF_merge/Poc_gene_count_matrix.csv /Users/Danielle/Desktop/Putnam_Lab/Becker_E5/RAnalysis/Data/RNA-seq/Host


#copy transcript count matrix
scp danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/mapped/GTF_merge/transcript_count_matrix.csv /Users/Danielle/Desktop/Putnam_Lab/Becker_E5/RAnalysis/Data/RNA-seq/Host

```
