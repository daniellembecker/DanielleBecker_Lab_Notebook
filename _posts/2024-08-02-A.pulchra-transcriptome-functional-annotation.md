---
layout: post
title: Acropora pulchra Functional Annotation Workflow
date: 2024-08-02
category: [ Code ]
tag: [ RNA-seq, Bioinformatics, Acropora pulchra de novo transcriptome ]
projects: Heatwave - Gametogenesis ; E5 - Molecular Underpinnings
---

## Creating a functional annotation file for *Acropora pulchra* de novo transcriptome.

### **Goal**

The following document contains the bioinformatic pipeline used for the functional annotation of a *de novo* transcriptome for *A. pulchra*. Pipeline adapted from the [Trinotate wiki](https://github.com/Trinotate/Trinotate/wiki/Software-installation-and-data-required). Trinotate is a comprehensive annotation suite designed for automatic functional annotation of transcriptomes, particularly de novo assembled transcriptomes, from model or non-model organisms. Trinotate makes use of a number of different well referenced methods for functional annotation including homology search to known sequence data (BLAST+/SwissProt), protein domain identification (HMMER/PFAM), and leveraging various annotation databases (eggNOG/GO/Kegg databases). All functional annotation data derived from the analysis of transcripts is integrated into a SQLite database which allows fast efficient searching for terms with specific qualities related to a desired scientific hypothesis or a means to create a whole annotation report for a transcriptome.

All metadata and information for these projects can be found in this [repository](https://github.com/daniellembecker/A.pul_Heatwave/tree/master) and in these notebook posts of the [*de novo* transcriptome assembly](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-08-31-Acropora-pulchra-denovo-transcriptome.md) and the [extraction protocol](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-04-25-Acropora-pulchra-transcriptome-extraction-concentration.md) for the samples used in the assembly. These commands were compiled into bash scripts to run on the URI HPC [Andromeda](https://its.uri.edu/research-computing/using-andromeda/) server.


# Step 1: Obtain *de novo* transcriptome

I am using the *Acropora pulchra* *de novo* transcriptome assembled in [November 2023](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-08-31-Acropora-pulchra-denovo-transcriptome.md), following methods outlined for [transcript sequence reconstruction from RNA-Seq: reference generation and analysis with Trinity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875132/).

Location on Andromeda, the HPC server for URI:
```
cd /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/output/final_assembly/CD-HIT/stranded_assembly_cdhit.fasta

```

## Make folder structure for functional annotation pipeline

```
cd /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/

mkdir functional_annotation
cd functional_annotation

mkdir Trinotate
cd Trinotate

mkdir data
mkdir output
mkdir scripts

```

# Step 2: Access previously created open reading frame prediction and protein sequence prediction with Transdecoder and Transpredictor

Already created .gff3, .pep, and .cds files for the reference transcriptome in step 8 of my [A.pulchra RNASeq Workflow](https://github.com/daniellembecker/DanielleBecker_Lab_Notebook/blob/master/_posts/2023-01-01-A.pulchra-RNASeq-Workflow.md).

Steps followed:

#### 1) Create .gff3 files for predicted gene structures, .pep for predicted proteins, and .cds predicted coding sequences for your de novo transcriptome

#To include putative gene information in your Trinity analysis, you can use TransDecoder.LongOrfs and TransDecoder.Predict
#First step identifies likely coding regions (long open reading frames or ORFs) in your Trinity transcripts and creates a file named Trinity.fasta.transdecoder_dir/longest_orfs.pep, which contains the predicted protein sequences.

#Second step predicts likely coding regions and identifies potential coding regions using the output from the LongOrfs step and generates several output files in the Trinity.fasta.transdecoder_dir/ directory, including Trinity.fasta.transdecoder.cds (predicted coding sequences) and Trinity.fasta.transdecoder.gff3 (predicted gene structures in GFF3 format).

Directory for TransDecoder and Transpredictor output files:

```
cd /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/

```

# Step 3: Set up Trinotate environmental variables in Andromeda HPC

Export the location of our Trinotate installation so we can run the software from any directory:

```
export TRINOTATE_HOME=/opt/software/Trinotate/4.0.2-foss-2022a
export PATH=$TRINOTATE_HOME:$PATH

```

# Step 4: Load the sequence databases required for TRINOTATE_HOME

Trinotate relies heavily on SwissProt and Pfam, and custom protein files are generated as described below to be specifically used with Trinotate. You can obtain the protein database files by running this Trinotate build process. This step will download several data resources including the most current versions of swissprot, pfam, and other companion resources, create and populate a Trinotate boilerplate sqlite database (Trinotate.sqlite), and yield uniprot_sprot.pep file to be used with BLAST, and the Pfam-A.hmm.gz file to be used for Pfam searches. Run the build process like so:

    $TRINOTATE_HOME/Trinotate --create \
                          --db myTrinotate.sqlite \
                          --trinotate_data_dir /path/to/TRINOTATE_DATA_DIR \
                          --use_diamond

where /path/to/TRINOTATE_DATA_DIR is the directory where you want all the Trinotate data resources to be installed -- and should not be your current working directory, but can be a destionation directory found within your current working directory (ie. $PWD != /path/to/TRINOTATE_DATA_DIR)

the --db myTrinotate.sqlite (or whatever you name it based on your target transcriptome) is what should be used for subsequent Trinotate commands below.

include --use_diamond if you plan to use diamond blast with Trinotate, otherwise NCBI blast+ will be used for database preparation.

and once it completes, it will create the 'myTrinotate.sqlite' database in your current working directory, and you'll find resources added to the TRINOTATE_DATA_DIR including:

uniprot_sprot.pep
Pfam-A.hmm.gz

Create script and run:

```
nano /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_database_build.sh


#!/bin/bash
#SBATCH --job-name=Trinotate      # Job name
#SBATCH --time=72:00:00                  # Time limit: 3 days
#SBATCH --nodes=1                           # Number of nodes
#SBATCH --ntasks-per-node=1                 # Number of tasks per node
#SBATCH --exclusive                         # Exclusive node allocation
#SBATCH --export=NONE                       # Do not export the environment
#SBATCH --mem=150GB                         # Memory allocation
#SBATCH --mail-type=BEGIN,END,FAIL           # Send email notifications
#SBATCH --mail-user=danielle_becker@uri.edu  # Email address for notifications
#SBATCH --account=putnamlab                 # Account to use
#SBATCH -D /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output
#SBATCH --error="script_error"              # File for error messages
#SBATCH --output="output_script"            # File for standard output

# Load necessary modules
module load Trinotate/4.0.2-foss-2022a
module load DIAMOND/2.1.9-GCC-13.2.0

# Set Trinotate environment variable
export TRINOTATE_HOME=/opt/software/Trinotate/4.0.2-foss-2022a

# Create Trinotate SQLite database and initialize with Diamond
$TRINOTATE_HOME/Trinotate --create \
  --db myTrinotate.sqlite \
  --trinotate_data_dir /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/data \
  --use_diamond

sbatch /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_database_build.sh

Submitted batch job 338474
```

# Step 5: Initialize your Trinotate sqlite database with your sequence data and filter my fasta for peptide protein coding regions for each transcript while selecting the longest predicted peptide sequences

The following inputs are required for Trinotate:

- transcripts.fasta : your target transcriptome in fasta format
- coding_seqs.pep : coding regions translated in fasta format (specific header formatting required - see below. Most use TransDecoder to generate this)
- gene_to_trans_map.tsv : pairwise mappings between gene and transcript isoform identifiers

If a Trinity reconstructed transcriptome is the target, then the transcripts.fasta and gene_to_trans_map.tsv are the final products of running Trinity. The coding_seqs.pep is derived from running TransDecoder to predict coding regions within the transcripts.

To select only protein coding transcripts and longest predicted peptide sequences:

First, extract the .pep ids

```
grep '^>' /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/stranded_assembly_cdhit.fasta.transdecoder.pep | sed 's/^>//' > pep_base_ids.txt

#remove the > character

sed 's/^>//' pep_base_ids.txt > cleaned_pep_base_ids.txt
```

Next, filter the .fasta file for only the ids found in the .pep files

```
interactive

module load SeqKit/2.3.1

seqtk subseq stranded_assembly_cdhit.fasta cleaned_pep_base_ids.txt > filtered_stranded_assembly_cdhit.fasta


```

Next, filter any duplicate .pep ids from the fasta file by selecting the longest longest predicted peptide sequences

```
# create file with peptide peptide_lengths

awk '/^>/ {header=$0; getline seq; print header "\t" length(seq)}' /data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/stranded_assembly_cdhit.fasta.transdecoder.pep > peptide_lengths.txt

# extract longest predicted peptide sequence

awk '{
    split($1, id, ".p");
    gene_id=id[1];
    len = $NF; # Length is the last field
    if (len > max_len[gene_id]) {
        max_len[gene_id] = len;
        longest_peptide[gene_id] = $1; # Store the full peptide ID
    }
}
END {
    for (gene in longest_peptide)
        print longest_peptide[gene];
}' peptide_lengths.txt > longest_peptide_ids.txt



#remove the > character

sed 's/^>//; s/\..*//' longest_peptide_ids.txt > cleaned_longest_peptide_ids.txt


# make final fasta

seqtk subseq stranded_assembly_cdhit.fasta cleaned_longest_peptide_ids.txt > final_filtered_stranded_assembly_cdhit.fasta
```


Create script and run:

```
nano /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_sqlite.sh


#!/bin/bash
#SBATCH --job-name=Trinotate_sqlite           # Job name
#SBATCH --time=72:00:00                       # Time limit: 3 days
#SBATCH --nodes=1                             # Number of nodes
#SBATCH --ntasks-per-node=1                   # Number of tasks per node
#SBATCH --exclusive                           # Exclusive node allocation
#SBATCH --export=NONE                         # Do not export the environment
#SBATCH --mem=150GB                           # Memory allocation
#SBATCH --mail-type=BEGIN,END,FAIL            # Send email notifications
#SBATCH --mail-user=danielle_becker@uri.edu   # Email address for notifications
#SBATCH --account=putnamlab                   # Account to use
#SBATCH -D /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output
#SBATCH --error="script_error_sqlite.err"     # File for error messages
#SBATCH --output="output_script_sqlite.out"   # File for standard output

# Load Trinotate and SQLite modules
module load Trinotate/4.0.2-foss-2022a
module load SQLite/3.36-GCCcore-11.2.0

# Set paths for inputs
TRANSCRIPTS=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/output/final_assembly/CD-HIT/final_filtered_stranded_assembly_cdhit.fasta
PEP_FILE=/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/stranded_assembly_cdhit.fasta.transdecoder.pep
GENE_MAP=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/output/final_assembly/CD-HIT/stranded_assembly_cdhit.fasta.gene_trans_map
TRINOTATE_DB=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output/myTrinotate.sqlite

# Initialize Trinotate SQLite database
Trinotate --db $TRINOTATE_DB --init \
    --gene_trans_map $GENE_MAP \
    --transcript_fasta $TRANSCRIPTS \
    --transdecoder_pep $PEP_FILE


sbatch /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_sqlite.sh


```

# Step 6: Run sequence analysis using BLAST, Pfam, SignalP, and other tools, and loads the results into the Trinotate database

To run the sequence analyses and database searches, simply run Trinotate like so:

    Trinotate --db <sqlite.db> --CPU <int> \
               --transcript_fasta <file> \
               --transdecoder_pep <file> \
               --trinotate_data_dir /path/to/TRINOTATE_DATA_DIR
               --run "swissprot_blastp swissprot_blastx pfam signalp6 tmhmmv2 infernal EggnogMapper" \
               --use_diamond

where, under --run, the list of analyses to perform are indicated within a quoted list. Of course, the required tools for performing each analysis should be installed as per above.

setting '--run ALL' is shorthand and equivalent to the above --run list.

parameter -E or --evalue can be used to set the E-value threshold for blast searches (default: 1e-5)

When the Trinotate --run is used to perform analyses, the results are automatically loaded into the Trinotate sqlite database.

If you need to run TmHMM or signalP separately (due to licensing issues), instructions are provided separately here.


Create script and run:

```
nano /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_sequences.sh


#!/bin/bash
#SBATCH --job-name=Trinotate_sequences          # Job name
#SBATCH --time=72:00:00                       # Time limit: 3 days
#SBATCH --nodes=1                             # Number of nodes
#SBATCH --ntasks-per-node=1                   # Number of tasks per node
#SBATCH --exclusive                           # Exclusive node allocation
#SBATCH --export=NONE                         # Do not export the environment
#SBATCH --mem=120GB                           # Memory allocation
#SBATCH --mail-type=BEGIN,END,FAIL            # Send email notifications
#SBATCH --mail-user=danielle_becker@uri.edu   # Email address for notifications
#SBATCH --account=putnamlab                   # Account to use
#SBATCH -D /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output
#SBATCH --error="script_error_sequences.err"     # File for error messages
#SBATCH --output="output_script_sequences.out"   # File for standard output

# Load Trinotate and SQLite modules
module load Trinotate/4.0.2-foss-2022a
module load DIAMOND/2.1.0-GCC-11.3.0
module load HMMER/3.3.2-iimpi-2021b

# Set paths for inputs and Trinotate database
TRANSCRIPTS=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/output/final_assembly/CD-HIT/final_filtered_stranded_assembly_cdhit.fasta
PEP_FILE=/data/putnamlab/dbecks/Heatwave_A.pul_2022Project/data/trinity/stranded_assembly_cdhit.fasta.transdecoder.pep
GENE_MAP=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/output/final_assembly/CD-HIT/stranded_assembly_cdhit.fasta.gene_trans_map
TRINOTATE_DB=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output/myTrinotate.sqlite
TRINOTATE_DATA_DIR=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/data

# Run sequence analyses using Trinotate
Trinotate --db $TRINOTATE_DB --CPU 8 \
    --transcript_fasta $TRANSCRIPTS \
    --transdecoder_pep $PEP_FILE \
    --trinotate_data_dir $TRINOTATE_DATA_DIR \
    --run "swissprot_blastp swissprot_blastx pfam infernal EggnogMapper" \
    --use_diamond


sbatch /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_sequences.sh


```

# Step 7:  Generate the Trinotate Report
The Trinotate annotation report is generated using the --report parameter like so:

      Trinotate --db <sqlite.db> --report [ -E (default: 1e-5) ]
                    [--pfam_cutoff DNC|DGC|DTC|SNC|SGC|STC (default: DNC=domain noise cutoff)]
                    [--incl_pep]
                    [--incl_trans]

an an example command might look like so:

     Trinotate --db myTrinotate.sqlite --report > myTrinotate.tsv

The report is a tab-delimited output with the following columns:

0       #gene_id
1       transcript_id
2       sprot_Top_BLASTX_hit
3       infernal
4       prot_id
5       prot_coords
6       sprot_Top_BLASTP_hit
7       Pfam
8       SignalP
9       TmHMM
10      eggnog
11      Kegg
12      gene_ontology_BLASTX
13      gene_ontology_BLASTP
14      gene_ontology_Pfam
15      transcript # optional, use --incl_trans
16      peptide # optional, use --incl_pep

The formatting of the data fields is somewhat intuitive and relatively easy to parse. Missing data or NULL results are indicated by '.' placeholders.

If EggnogMapper is included, the EggnogMapper results are further integrated into this tabulated output with an expanded set of columns and easily identified as derived accordingly.

Create script and run:

```
nano /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_report.sh


#!/bin/bash
#SBATCH --job-name=Trinotate_report          # Job name
#SBATCH --time=72:00:00                       # Time limit: 3 days
#SBATCH --nodes=1                             # Number of nodes
#SBATCH --ntasks-per-node=1                   # Number of tasks per node
#SBATCH --exclusive                           # Exclusive node allocation
#SBATCH --export=NONE                         # Do not export the environment
#SBATCH --mem=150GB                           # Memory allocation
#SBATCH --mail-type=BEGIN,END,FAIL            # Send email notifications
#SBATCH --mail-user=danielle_becker@uri.edu   # Email address for notifications
#SBATCH --account=putnamlab                   # Account to use
#SBATCH -D /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output
#SBATCH --error="script_error_report.err"     # File for error messages
#SBATCH --output="output_script_report.out"   # File for standard output

# Load Trinotate and SQLite modules
module load Trinotate/4.0.2-foss-2022a

# Set paths for inputs and Trinotate database
TRINOTATE_DB=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output/myTrinotate.sqlite
REPORT_FILE=/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output/myTrinotate_report.tsv

# Generate the Trinotate annotation report
Trinotate --db $TRINOTATE_DB --report > $REPORT_FILE


sbatch /data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/scripts/Trinotate_report.sh


```

# Step 8:  Download functional annotation to local computer

```
scp -r danielle_becker@ssh3.hac.uri.edu:/data/putnamlab/dbecks/DeNovo_transcriptome/2023_A.pul/functional_annotation/Trinotate/output/myTrinotate_report.tsv /Users/Danielle/Desktop/Putnam_Lab/A.pul_Heatwave/bioinformatics/data
```
